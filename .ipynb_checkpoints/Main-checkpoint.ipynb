{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf0c8d1b4479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# textes : acquisition met à jour la base de données des corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0macquisition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./CISI.ALLnettoye\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-bf0c8d1b4479>\u001b[0m in \u001b[0;36macquisition\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtexte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapMots\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtableTextes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtableTextes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtexte\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mtableTextes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtexte\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtableTextes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtableMotsGenerale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import operator\n",
    "\n",
    "# table renvoyant une liste de textes (sous forme d'ints représentant le numéro des textes) pour chaque mot\n",
    "tableMotsGenerale = {}\n",
    "# pour chaque numéro de texte renvoie le hashSet représentant les valeurs TFIDF de chaque mot\n",
    "tableTextes = {}\n",
    "\n",
    "\n",
    "def acquisition(path):\n",
    "    \n",
    "    f=open(path,'r')\n",
    "    \n",
    "    # masque pour détecter les débuts de textes\n",
    "    regexp=re.compile(\"^\\.I\\s*([0-9]*)\\s*\")\n",
    "    \n",
    "    # numéro du texte courant, valeur abérante par défaut\n",
    "    numero = -1\n",
    "    \n",
    "    # tableau contenant chaque ligne du fichier\n",
    "    listeLignes = f.readlines()\n",
    "    \n",
    "    # le nombre de mots rencontrés\n",
    "    nombreMots = 0\n",
    "    \n",
    "    \n",
    "    for ligne in listeLignes:\n",
    "        # supprime les espaces et sauts de lignes en début et fin de chaîne\n",
    "        ligne.lstrip\n",
    "        ligne.rstrip(\"\\n\")\n",
    "        \n",
    "        # on cherche la marque du début d'un nouveau ou du premier texte\n",
    "        result = regexp.search(ligne)\n",
    "        if result != None:\n",
    "            # teste si on a déjà rencontré un texte avant\n",
    "            if numero != -1:\n",
    "                for mot,valeur in tableTextes[numero].items():\n",
    "                    # TF, sans IDF car il manque le nombre de textes dans lesquels le mot apparait\n",
    "                    tableTextes[numero][mot]=(valeur/nombreMots)\n",
    "            # on capture son index \n",
    "            numero = int(result.group(1))\n",
    "            # on initialise sa table de mots\n",
    "            tableTextes[numero] = {}\n",
    "             # on initialise le nombre de mots de celui-ci\n",
    "            nombreMots = 0\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # on casse la ligne du document\n",
    "            mots = ligne.split()\n",
    "            \n",
    "            for mot in mots:\n",
    "                nombreMots+=1\n",
    "                # on supprime la ponctuation éventuelle\n",
    "                mot = re.sub(\"[\\.,;:\\?!]\",\"\",mot)\n",
    "                # si le mot existe déjà dans la table on augmente son nombre d'apparitions\n",
    "                if mot in tableTextes[numero]:\n",
    "                    tableTextes[numero][mot]+=1\n",
    "                # dans le cas contraire on ajoute le mot dans la table\n",
    "                else:\n",
    "                    tableTextes[numero][mot]=1\n",
    "                    # si le mot a déjà été vu pour un autre texte, on ajoute ce texte dans la table générale\n",
    "                    if mot in tableMotsGenerale:\n",
    "                        tableMotsGenerale[mot].append(numero)\n",
    "                    # sinon on ajoute le mot dans la table générale et on y associe ce texte\n",
    "                    else:\n",
    "                        tableMotsGenerale[mot]=[numero]\n",
    "\n",
    "    # on a parcouru tous les termes, on peut appliquer l'IDF du TFIDF au TF\n",
    "    for texte,mapMots in tableTextes.items():\n",
    "        for mot,tf in tableTextes[texte].items():\n",
    "            tableTextes[texte][mot]*=math.log(len(tableTextes)/len(tableMotsGenerale[mot]))\n",
    "    \n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return\n",
    "\n",
    "# textes : acquisition met à jour la base de données des corpus\n",
    "acquisition(\"./CISI.ALLnettoye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitementRequete(Requete):\n",
    "    # Donne, pour chaque texte, un score de pertinance par rapport à la requête\n",
    "    scores = {}\n",
    "    \n",
    "    # Calcul des scores\n",
    "    mots = Requete.split()\n",
    "    # trouve le score max\n",
    "    max = 0\n",
    "    for mot in mots:\n",
    "        # on supprime la ponctuation éventuelle\n",
    "        mot = re.sub(\"[\\.,;:\\?!]\",\"\",mot)\n",
    "        if mot in tableMotsGenerale:\n",
    "            listeTextes = tableMotsGenerale[mot]\n",
    "            for texte in listeTextes:\n",
    "                if texte in scores:\n",
    "                    scores[texte]+=tableTextes[texte][mot]\n",
    "                else:\n",
    "                    scores[texte]=tableTextes[texte][mot]\n",
    "                if scores[texte] > max:\n",
    "                    max = scores[texte]\n",
    "\n",
    "                \n",
    "    \n",
    "    # enlève les textes avec un petit score (inférieur à la moitié du meilleur)\n",
    "    copie = dict(scores)\n",
    "    for texte,score in scores.items():\n",
    "        if score<(max/2):\n",
    "            del copie[texte]\n",
    "    scores = copie\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def printScores(scores):\n",
    "    print((sorted(scores.items(), key=operator.itemgetter(1)))[::-1])\n",
    "\n",
    "scores = traitementRequete(\"Dewey\")\n",
    "printScores(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisitionDesRequetes(path):\n",
    "    f=open(path,'r')\n",
    "    \n",
    "    # si true, on capture une requête\n",
    "    catch = False\n",
    "    \n",
    "    # Table contenant pour chaque numéro de requête un texte de requête\n",
    "    tableRequete={}\n",
    "    \n",
    "    # masque pour détecter les numéros de requêtes\n",
    "    regexNumero=re.compile(\"^\\.I\\s*([0-9]*)\\s*\")\n",
    "    \n",
    "    # masque pour détecter les débuts de requêtes\n",
    "    regexContenu=re.compile(\"^\\.W\")\n",
    "    \n",
    "    # masque pour détecter les fins de requêtes\n",
    "    regexFinCatch=re.compile(\"^\\.[BI]\")\n",
    "    \n",
    "    # numéro de la requête courante\n",
    "    numero = 1\n",
    "    \n",
    "    # tableau contenant chaque ligne du fichier\n",
    "    listeLignes = f.readlines()\n",
    "    \n",
    "    for ligne in listeLignes:\n",
    "        # supprime les espaces et sauts de lignes en début et fin de chaîne\n",
    "        ligne.lstrip\n",
    "        ligne.rstrip(\"\\n\")\n",
    "        \n",
    "        # fin de texte\n",
    "        result = regexFinCatch.search(ligne)\n",
    "        if result != None:\n",
    "            catch = False\n",
    "        \n",
    "        if catch:\n",
    "            tableRequete[numero]+=ligne\n",
    "        \n",
    "        # numero de requête\n",
    "        result = regexNumero.search(ligne)\n",
    "        if result != None:\n",
    "            # on capture son index \n",
    "            numero = int(result.group(1))\n",
    "            # on initialise son contenu\n",
    "            tableRequete[numero] = \"\"\n",
    "        # debut de texte\n",
    "        result = regexContenu.search(ligne)\n",
    "        if result != None:\n",
    "            catch = True\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "    return tableRequete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluationListeRequetes(listeRequetes):\n",
    "    listeScoresRequetes = {}\n",
    "    for numero,requete in listeRequetes.items():\n",
    "        listeScoresRequetes[numero] = traitementRequete(requete)\n",
    "    #print(listeScoresRequetes[8])    \n",
    "    return listeScoresRequetes\n",
    "        \n",
    "\n",
    "def ecrireListeScoresRequetes(path,listeScoresRequetes):\n",
    "    f=open(path,'w')\n",
    "    for numeroRequete,scores in listeScoresRequetes.items():\n",
    "        for numeroTexte,score in scores.items():\n",
    "            f.write(str(numeroRequete)+\" \"+str(numeroTexte)+\" \"+str(score)+'\\n')\n",
    "    \n",
    "    \n",
    "    f.close()\n",
    "    return\n",
    "\n",
    "# textes : acquisition met à jour la base de données des corpus\n",
    "acquisition(\"./CISI.ALLnettoye\")\n",
    "# requêtes : ecrireListeScoresRequetes écrit dans un fichier le score de pertinence pour chaque texte obtenu \n",
    "# pour chaque requête (evaluationlisteRequetes apelle traitementRequete sur chaque requête venant de\n",
    "# acquisitionDesRequetes)\n",
    "ecrireListeScoresRequetes(\"./resultats\",evaluationListeRequetes(acquisitionDesRequetes(\"./CISI_dev.QRY\")))\n",
    "\n",
    "# Evaluer les résultats avec le script perl : ./eval.pl CISI_dev.REL resultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
